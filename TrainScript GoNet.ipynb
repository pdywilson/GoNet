{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TrainScript GoNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import IPython.display\n",
    "import sqlite3\n",
    "import io\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "def convert_array(text):\n",
    "    out = io.BytesIO(text)\n",
    "    out.seek(0)\n",
    "    return np.load(out)\n",
    "\n",
    "# Converts TEXT to np.array when selecting\n",
    "sqlite3.register_converter(\"array\", convert_array)\n",
    "\n",
    "con = sqlite3.connect(r\"DB/Move/dan_data_295\", detect_types=sqlite3.PARSE_DECLTYPES)\n",
    "cur = con.cursor()\n",
    "cur.execute(\"SELECT * FROM movedata\")\n",
    "data = cur.fetchall()\n",
    "con.close()\n",
    "\n",
    "# get rid of index of db_entry and create N*892-dim input array\n",
    "for ind in range(len(data)):\n",
    "    data[ind] = np.concatenate(data[ind][1:])\n",
    "\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15704, 9, 9)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[:,:81].reshape((d2.shape[0],9,9)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 1, 9, 9]), torch.Size([1000, 82]))"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load all data, shape is 81 input 82 output 162: filtered boards\n",
    "numberOfSamples = 1000\n",
    "labels = torch.LongTensor(loadedData[:numberOfSamples,81:163])\n",
    "data = torch.FloatTensor(loadedData[:numberOfSamples,:81].reshape((numberOfSamples,9,9)))\n",
    "data = data.unsqueeze(1) # add fake batch dimension\n",
    "data.shape, labels.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "\n",
    "train = data_utils.TensorDataset(data, labels)\n",
    "train_loader = data_utils.DataLoader(train, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 12, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=300, out_features=82, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# the Classifier stolen from Pytorch Tutorial\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3 square convolution\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 12, 3)\n",
    "        \n",
    "        # output channels 36 * (5 * 5) -> output per channel  \n",
    "        self.fc1 = nn.Linear(12 * 5 * 5, 82)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        # Flatten 2d array to pass to linear layer, -1 works for arbitrary #rows which can vary with batchsize\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, torch.max(labels,1)[1])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1568, -0.5298, -0.4719, -0.7667, -1.5456, -0.5871, -0.4048, -0.5829,\n",
       "         -1.0691, -0.6141, -0.0178,  0.2488,  0.5656, -0.2305,  0.5626,  0.2647,\n",
       "         -0.0071, -0.4808, -0.5404,  0.1986,  0.8091,  0.6497,  0.5500,  0.6345,\n",
       "          0.8404,  0.2590, -0.4320, -0.6044,  0.5514,  0.6463,  0.6456,  0.6316,\n",
       "          0.6528,  0.6508,  0.5466, -0.7506, -1.5295, -0.2022,  0.5426,  0.6240,\n",
       "          0.3698,  0.6360,  0.5557, -0.2558, -1.4251, -0.5772,  0.5691,  0.6594,\n",
       "          0.6433,  0.6303,  0.6183,  0.6626,  0.5764, -0.6674, -0.4320,  0.2799,\n",
       "          0.8504,  0.6342,  0.5417,  0.6337,  0.8542,  0.2112, -0.4178, -0.6264,\n",
       "         -0.0202,  0.2144,  0.5566, -0.2272,  0.5484,  0.2662, -0.0302, -0.6856,\n",
       "         -1.1484, -0.5921, -0.3418, -0.6853, -1.5480, -0.6850, -0.4884, -0.5753,\n",
       "         -1.1595,  1.3502]], grad_fn=<ThAddmmBackward>)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(torch.FloatTensor(np.zeros((9,9))).unsqueeze(0).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
